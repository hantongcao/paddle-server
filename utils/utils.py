import cv2
import os
import numpy as np
import fitz  # PyMuPDF
import base64
import requests
import pathlib
import shutil
# åŠ¨æ€å¯¼å…¥é…ç½®ï¼Œæ”¯æŒç›´æ¥è¿è¡Œå’ŒåŒ…å¯¼å…¥ä¸¤ç§æ–¹å¼
try:
    from ..config.config import DEFAULT_LONGEST_SIDE
except ImportError:
    # ç›´æ¥è¿è¡Œæ—¶ä½¿ç”¨ç»å¯¹å¯¼å…¥
    import sys
    import os
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
    from config.config import DEFAULT_LONGEST_SIDE

def resize_longest_side(image, longest_side=DEFAULT_LONGEST_SIDE):
    """
    ç¼©æ”¾å›¾åƒï¼Œæœ€é•¿çš„è¾¹ä¸ºæŒ‡å®šåƒç´ 
    
    Args:
        image: è¾“å…¥çš„cv2å›¾åƒå¯¹è±¡
        longest_side (int): æœ€é•¿è¾¹çš„åƒç´ å¤§å°ï¼Œé»˜è®¤ä¸º1280
        
    Returns:
        ç¼©æ”¾åçš„cv2å›¾åƒå¯¹è±¡
    """
    # è·å–åŸå§‹å°ºå¯¸
    height, width = image.shape[:2]
    
    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
    if width > height:
        # å®½åº¦æ˜¯é•¿è¾¹
        scale = longest_side / width
        new_width = longest_side
        new_height = int(height * scale)
    else:
        # é«˜åº¦æ˜¯é•¿è¾¹
        scale = longest_side / height
        new_height = longest_side
        new_width = int(width * scale)
    
    # ç¼©æ”¾å›¾åƒ
    resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)
    
    return resized_image

def encode_image_to_base64(image_input):
    """
    å°†å›¾åƒç¼–ç ä¸ºBase64å­—ç¬¦ä¸²ï¼Œæ”¯æŒæ–‡ä»¶è·¯å¾„æˆ–cv2å›¾åƒå¯¹è±¡
    
    Args:
        image_input (str or numpy.ndarray): å›¾åƒæ–‡ä»¶è·¯å¾„æˆ–cv2å›¾åƒå¯¹è±¡
        
    Returns:
        str: Base64ç¼–ç çš„å›¾åƒå­—ç¬¦ä¸²
        
    Raises:
        TypeError: å¦‚æœè¾“å…¥ç±»å‹ä¸æ”¯æŒ
    """
    if isinstance(image_input, str):
        # è¾“å…¥æ˜¯æ–‡ä»¶è·¯å¾„
        with open(image_input, "rb") as file:
            image_bytes = file.read()
            image_data = base64.b64encode(image_bytes).decode("ascii")
        return image_data
    elif hasattr(image_input, 'dtype') and hasattr(image_input, 'shape'):
        # è¾“å…¥æ˜¯numpyæ•°ç»„ï¼ˆcv2å›¾åƒå¯¹è±¡ï¼‰
        success, encoded_image = cv2.imencode('.png', image_input)
        if not success:
            raise ValueError("Failed to encode image to PNG format")
        image_bytes = encoded_image.tobytes()
        image_data = base64.b64encode(image_bytes).decode("ascii")
        return image_data
    else:
        raise TypeError("Unsupported input type. Expected file path (str) or cv2 image object (numpy.ndarray)")

def create_layout_parsing_payload(image_data, file_type=1):
    """
    åˆ›å»ºå¸ƒå±€è§£æAPIçš„è¯·æ±‚è´Ÿè½½
    
    Args:
        image_data (str): Base64ç¼–ç çš„å›¾åƒæ•°æ®æˆ–æ–‡ä»¶URL
        file_type (int): æ–‡ä»¶ç±»å‹ï¼Œ1è¡¨ç¤ºå›¾åƒæ–‡ä»¶
        
    Returns:
        dict: APIè¯·æ±‚è´Ÿè½½
    """
    return {
        "file": image_data,
        "fileType": file_type
    }

def call_layout_parsing_api(api_url, payload):
    """
    è°ƒç”¨å¸ƒå±€è§£æAPI
    
    Args:
        api_url (str): APIç«¯ç‚¹URL
        payload (dict): è¯·æ±‚è´Ÿè½½
        
    Returns:
        requests.Response: APIå“åº”å¯¹è±¡
    """
    response = requests.post(api_url, json=payload)
    return response

def process_layout_parsing_result(response):
    """
    å¤„ç†å¸ƒå±€è§£æAPIçš„è¿”å›ç»“æœ
    
    Args:
        response (requests.Response): APIå“åº”å¯¹è±¡
        
    Returns:
        dict: è§£æåçš„ç»“æœæ•°æ®
    """
    assert response.status_code == 200
    return response.json()["result"]

def pdf_to_images(pdf_input, output_dir="temp_images", dpi=300):
    """
    å°†PDFæ–‡ä»¶æŒ‰é¡µè½¬æ¢ä¸ºPNGå›¾åƒï¼ˆä½¿ç”¨PyMuPDFæ›¿ä»£pdf2imageï¼‰
    
    Args:
        pdf_input (str or file-like object): PDFæ–‡ä»¶è·¯å¾„æˆ–æ–‡ä»¶å¯¹è±¡
        output_dir (str): è¾“å‡ºç›®å½•
        dpi (int): å›¾åƒåˆ†è¾¨ç‡ï¼ˆä»…ä¸ºäº†æ¥å£å…¼å®¹æ€§ï¼‰
        
    Returns:
        list: ç”Ÿæˆçš„å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    pathlib.Path(output_dir).mkdir(exist_ok=True)
    
    image_paths = []
    
    # ä½¿ç”¨PyMuPDFæ‰“å¼€PDF - æ”¯æŒæ–‡ä»¶è·¯å¾„æˆ–æ–‡ä»¶å¯¹è±¡
    if isinstance(pdf_input, str):
        # è¾“å…¥æ˜¯æ–‡ä»¶è·¯å¾„
        doc = fitz.open(pdf_input)
    else:
        # è¾“å…¥æ˜¯æ–‡ä»¶å¯¹è±¡
        # å…ˆå°†æ–‡ä»¶å†…å®¹è¯»å–åˆ°å†…å­˜ä¸­ï¼Œç„¶åä½¿ç”¨fitz.openæ‰“å¼€
        pdf_content = pdf_input.read()
        doc = fitz.open("pdf", pdf_content)
    
    for i in range(len(doc)):
        # è·å–é¡µé¢
        page = doc.load_page(i)
        
        # å°†é¡µé¢è½¬æ¢ä¸ºå›¾åƒï¼ˆçŸ©é˜µï¼‰
        mat = fitz.Matrix(2.0, 2.0)  # ç¼©æ”¾å› å­ï¼Œ2.0è¡¨ç¤º200%è´¨é‡
        pix = page.get_pixmap(matrix=mat)
        
        # ä¿å­˜å›¾åƒ
        image_path = pathlib.Path(output_dir) / f"page_{i+1:03d}.png"
        pix.save(str(image_path))
        image_paths.append(str(image_path))
        
        print(f"Saved page {i+1} as {image_path}")
    
    doc.close()
    return image_paths

def extract_markdown_from_result(result):
    """
    ä»APIç»“æœä¸­æå–markdownå†…å®¹
    
    Args:
        result (dict): APIè¿”å›çš„ç»“æœ
        
    Returns:
        dict: åŒ…å«markdownå†…å®¹çš„å­—å…¸ï¼Œæ ¼å¼ä¸º {'pageX': 'markdownå†…å®¹'}
    """
    markdown_dict = {}
    
    for i, res in enumerate(result["layoutParsingResults"]):
        page_key = f"page{i+1}"
        markdown_dict[page_key] = res["markdown"]["text"]
    
    return markdown_dict

def process_pdf_file(pdf_input, api_url, longest_side=1280):
    """
    å¤„ç†PDFæ–‡ä»¶ï¼šè½¬æ¢ã€è°ƒæ•´å¤§å°ã€è§£æå¸ƒå±€ï¼Œç›´æ¥è¿”å›markdownå†…å®¹
    
    Args:
        pdf_input (str or file-like object): PDFæ–‡ä»¶è·¯å¾„æˆ–æ–‡ä»¶å¯¹è±¡
        api_url (str): å¸ƒå±€è§£æAPI URL
        longest_side (int): æœ€é•¿è¾¹åƒç´ å¤§å°
        
    Returns:
        dict: åŒ…å«æ‰€æœ‰é¡µé¢markdownå†…å®¹çš„å­—å…¸ï¼Œæ ¼å¼ä¸º {'page1': 'å†…å®¹', 'page2': 'å†…å®¹', ...}
    """
    # åˆ›å»ºä¸´æ—¶å›¾åƒç›®å½•
    temp_dir = "temp_pdf_images"
    
    try:
        # 1. è½¬æ¢PDFä¸ºå›¾åƒ
        print(f"Converting PDF to images...")
        image_paths = pdf_to_images(pdf_input, temp_dir)
        print(f"âœ“ PDFè½¬æ¢å®Œæˆï¼Œå…± {len(image_paths)} é¡µ")
        
        all_markdowns = []
        
        for i, image_path in enumerate(image_paths):
            print(f"\n--- å¤„ç†ç¬¬ {i+1}/{len(image_paths)} é¡µ ---")
            print(f"Processing image: {image_path}")
            
            # 2. è¯»å–å›¾åƒå¹¶è°ƒæ•´å¤§å°
            image = cv2.imread(image_path)
            if image is None:
                print(f"âŒ è¯»å–å›¾åƒå¤±è´¥: {image_path}")
                continue
                
            original_size = image.shape[:2]
            resized_image = resize_longest_side(image, longest_side)
            resized_size = resized_image.shape[:2]
            print(f"âœ“ å›¾åƒè°ƒæ•´å¤§å°: {original_size} â†’ {resized_size}")
            
            # 3. ç¼–ç ä¸ºBase64
            image_data = encode_image_to_base64(resized_image)
            print(f"âœ“ Base64ç¼–ç å®Œæˆï¼Œæ•°æ®é•¿åº¦: {len(image_data)} å­—ç¬¦")
            
            # 4. åˆ›å»ºè´Ÿè½½å¹¶è°ƒç”¨API
            payload = create_layout_parsing_payload(image_data)
            print(f"âœ“ è¯·æ±‚è´Ÿè½½åˆ›å»ºå®Œæˆ")
            
            response = call_layout_parsing_api(api_url, payload)
            print(f"âœ“ APIè°ƒç”¨æˆåŠŸï¼ŒçŠ¶æ€ç : {response.status_code}")
            
            # 5. å¤„ç†ç»“æœå¹¶æå–markdown
            result = process_layout_parsing_result(response)
            page_markdowns = extract_markdown_from_result(result)
            
            # æ˜¾ç¤ºæå–çš„markdownç»Ÿè®¡ä¿¡æ¯
            for page_name, content in page_markdowns.items():
                char_count = len(content)
                line_count = content.count('\n') + 1
                print(f"âœ“ æå– {page_name}: {char_count} å­—ç¬¦, {line_count} è¡Œ")
            
            # åˆå¹¶åˆ°æ€»ç»“æœä¸­ - ç”Ÿæˆè¦æ±‚çš„JSONæ ¼å¼
            for page_name, content in page_markdowns.items():
                page_json = {
                    "page": i + 1,
                    "ocrContent": {
                        "backend": "pipeline",
                        "version": "2.5.4",
                        "results": {
                            "image": {
                                "md_content": content
                            }
                        }
                    }
                }
                all_markdowns.append(page_json)
            print(f"âœ“ ç¬¬ {i+1} é¡µå¤„ç†å®Œæˆ")
            
        print(f"\nğŸ‰ æ‰€æœ‰é¡µé¢å¤„ç†å®Œæˆ!")
        print(f"æ€»é¡µæ•°: {len(all_markdowns)}")
        total_chars = sum(len(page["ocrContent"]["results"]["image"]["md_content"]) for page in all_markdowns)
        print(f"æ€»å­—ç¬¦æ•°: {total_chars}")
        
        # è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
        import json
        json_output = json.dumps(all_markdowns, ensure_ascii=False, indent=2)
        print(f"âœ“ JSONè¾“å‡ºå®Œæˆï¼Œå…± {len(json_output)} å­—ç¬¦")
        print(f"JSONè¾“å‡ºé¢„è§ˆ:\n{json_output[:20000]}...")  # æ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦
        return json_output
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if pathlib.Path(temp_dir).exists():
            shutil.rmtree(temp_dir)


